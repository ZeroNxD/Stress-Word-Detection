{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dependencies Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: click in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: colorama in d:\\semester 4\\natural language processing\\lab praktikum\\environments\\nlp\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing List of the Stopwords in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset from CSV\n",
    "Stres_Data = pd.read_csv('D:\\\\Semester 4\\\\Natural Language Processing\\\\Lab Praktikum\\\\Research Methodology Project\\\\Stress.csv', encoding='ISO-8859-1')\n",
    "Stres_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "1        assistance  8lbrx9         (0, 5)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "\n",
       "                                                text  label  confidence  \\\n",
       "0  He said he had not felt that way before, sugge...      1         0.8   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0         1.0   \n",
       "2  My mom then hit me with the newspaper and it s...      1         0.8   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1         0.6   \n",
       "4  October is Domestic Violence Awareness Month a...      1         0.8   \n",
       "\n",
       "   social_timestamp  \n",
       "0        1521614353  \n",
       "1        1527009817  \n",
       "2        1535935605  \n",
       "3        1516429555  \n",
       "4        1539809005  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stres_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit           0\n",
       "post_id             0\n",
       "sentence_range      0\n",
       "text                0\n",
       "label               0\n",
       "confidence          0\n",
       "social_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Missing Value\n",
    "Stres_Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1488\n",
       "0    1350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Distribution of label index [Stres Level Index]\n",
    "Stres_Data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 --> Non-Stres Text\n",
    "\n",
    "1 --> Stres Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Imbalanced, so we need to do Upsampling or Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resample [UpSampling]\n",
      "(1488, 7)\n",
      "(1350, 7)\n",
      "After Resample [UpSampling]\n",
      "(1488, 7)\n",
      "(1488, 7)\n"
     ]
    }
   ],
   "source": [
    "# UpSampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "One_Sample = Stres_Data[Stres_Data['label'] == 1]\n",
    "Zero_Sample = Stres_Data[Stres_Data['label'] == 0]\n",
    "print(\"Before Resample [UpSampling]\")\n",
    "print(One_Sample.shape)\n",
    "print(Zero_Sample.shape)\n",
    "\n",
    "Zero_Sample = resample(Zero_Sample, replace=True, n_samples=len(One_Sample), random_state=42)\n",
    "print(\"After Resample [UpSampling]\")\n",
    "print(One_Sample.shape)\n",
    "print(Zero_Sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    1488\n",
       "0    1488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(One_Sample)\n",
    "df_2 = pd.DataFrame(Zero_Sample)\n",
    "\n",
    "Stres_Data = pd.concat([df_1, df_2])\n",
    "Stres_Data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming --> Process to Reduce a word into its root word\n",
    "\n",
    "Example like\n",
    "actor, actress, acting --> act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Porter_Stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) # Matching Pattern by removing everything except a-z and A-Z\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [Porter_Stemmer.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stres_Data['Stemmed_Text'] = Stres_Data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>said felt way sugget go rest trigger ahead you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "      <td>mom hit newspap shock would know like play hit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "      <td>met new boyfriend amaz kind sweet good student...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "      <td>octob domest violenc awar month domest violenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7tx7et</td>\n",
       "      <td>(30, 35)</td>\n",
       "      <td>I think he doesn't want to put in the effort f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1517274027</td>\n",
       "      <td>think want put effort relationship work diffic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "5     relationships  7tx7et       (30, 35)   \n",
       "\n",
       "                                                text  label  confidence  \\\n",
       "0  He said he had not felt that way before, sugge...      1         0.8   \n",
       "2  My mom then hit me with the newspaper and it s...      1         0.8   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1         0.6   \n",
       "4  October is Domestic Violence Awareness Month a...      1         0.8   \n",
       "5  I think he doesn't want to put in the effort f...      1         1.0   \n",
       "\n",
       "   social_timestamp                                       Stemmed_Text  \n",
       "0        1521614353  said felt way sugget go rest trigger ahead you...  \n",
       "2        1535935605  mom hit newspap shock would know like play hit...  \n",
       "3        1516429555  met new boyfriend amaz kind sweet good student...  \n",
       "4        1539809005  octob domest violenc awar month domest violenc...  \n",
       "5        1517274027  think want put effort relationship work diffic...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stres_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said felt way sugget go rest trigger ahead youi hypocondriac like decid look feel doom hope mayb get suck rabbit hole ludicr conspiraci stupid psychic test new age b someth could even laugh road end read sens doom indic variou health ailment one prone top doom gloom f n worri heart happen physic hour'\n",
      " 'mom hit newspap shock would know like play hit smack strike hit violenc sort person send vibe ask univers yesterday decid take friend go help anoth friend move new place drive friend move strike shoulder address immedi th time told thing friend drive nearli get collis anoth car think high marijuana friend move backseat like understand tri get attent know thing year old get peopl attent smack guy'\n",
      " 'met new boyfriend amaz kind sweet good student like thing famili like dont feel passion rush felt ex truth start go boyfriend secretli saw ex time see realli didnt feel noth disgust didnt even want touch feel bad didnt want still kinda realiz felt noth love relat ok hurt knew date boy even beg stay cours problem im boyfriend dont feel like love like thing kinda feel new love feel ok catch think ex time time rememb good thing drive crazi know see wont feel way love mind make think still recent found girl actual enjoy experi got mad hurt know dont right feel way felt betray still feel way gross'\n",
      " ...\n",
      " 'first long term seriou relationship time awar ask normal love everyth gave oldest greatest friendship guy love ruin alex alway bit flirti never made move one anoth would come relationship advic never feel would help wholeheartedli issu'\n",
      " 'hi year old scottish student studi contemporari art practic honour degre level anyon interest allow use word use project univers consequ psycholog abus victim incred tricki import subject portray art made sure research rather heavili subject affect mental abus well person experi make sure repres respect everyon went someth similar'\n",
      " 'hi r assist dad traumat brain injuri car accid two year ago victim anoth driver reckless neglig rear end twice stop stoplight forc retir perman disabl deal effect perman brain damag rest life dad requir constant caretak exhibit symptom similar alzheim dementia patient mom unabl work either']\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Separating Text and Label\n",
    "X = Stres_Data['Stemmed_Text'].values\n",
    "Y = Stres_Data['label'].values\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data to training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_test, Y_Train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Textual Data into Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_String = X_test\n",
    "X_Train = Vectorizer.fit_transform(X_Train)\n",
    "X_test = Vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training The Machine Learning Model [Logistic Regression, Random Forest, Decision Tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_Train, Y_Train)\n",
    "model1.fit(X_Train, Y_Train)\n",
    "model2.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Training Data:  0.9155462184873949\n"
     ]
    }
   ],
   "source": [
    "X_Train_Prediction = model.predict(X_Train)\n",
    "Training_Data_Accuracy = accuracy_score(Y_Train, X_Train_Prediction)\n",
    "print('Accuracy Score on the Training Data: ', Training_Data_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Test Data:  0.7818791946308725\n"
     ]
    }
   ],
   "source": [
    "X_Test_Prediction = model.predict(X_test)\n",
    "Test_Data_Accuracy = accuracy_score(Y_test, X_Test_Prediction)\n",
    "print('Accuracy Score on the Test Data: ', Test_Data_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       298\n",
      "           1       0.78      0.79      0.78       298\n",
      "\n",
      "    accuracy                           0.78       596\n",
      "   macro avg       0.78      0.78      0.78       596\n",
      "weighted avg       0.78      0.78      0.78       596\n",
      "\n",
      "[[231  67]\n",
      " [ 63 235]]\n",
      "0.5638091828819275\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, X_Test_Prediction))\n",
    "print(confusion_matrix(Y_test, X_Test_Prediction))\n",
    "print(matthews_corrcoef(Y_test, X_Test_Prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Training Data:  0.9995798319327731\n"
     ]
    }
   ],
   "source": [
    "X_Train_RFPrediction = model1.predict(X_Train)\n",
    "Training_Data_RFAccuracy = accuracy_score(Y_Train, X_Train_RFPrediction)\n",
    "print('Accuracy Score on the Training Data: ', Training_Data_RFAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Test Data:  0.8120805369127517\n"
     ]
    }
   ],
   "source": [
    "X_Test_RFPrediction = model1.predict(X_test)\n",
    "Test_Data_RFAccuracy = accuracy_score(Y_test, X_Test_RFPrediction)\n",
    "print('Accuracy Score on the Test Data: ', Test_Data_RFAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.80       298\n",
      "           1       0.77      0.89      0.83       298\n",
      "\n",
      "    accuracy                           0.81       596\n",
      "   macro avg       0.82      0.81      0.81       596\n",
      "weighted avg       0.82      0.81      0.81       596\n",
      "\n",
      "[[219  79]\n",
      " [ 33 265]]\n",
      "0.6317328381028974\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, X_Test_RFPrediction))\n",
    "print(confusion_matrix(Y_test, X_Test_RFPrediction))\n",
    "print(matthews_corrcoef(Y_test, X_Test_RFPrediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Training Data:  0.9995798319327731\n"
     ]
    }
   ],
   "source": [
    "X_Train_DTPrediction = model2.predict(X_Train)\n",
    "Training_Data_DTAccuracy = accuracy_score(Y_Train, X_Train_DTPrediction)\n",
    "print('Accuracy Score on the Training Data: ', Training_Data_DTAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on the Test Data:  0.7567114093959731\n"
     ]
    }
   ],
   "source": [
    "X_Test_DTPrediction = model2.predict(X_test)\n",
    "Test_Data_DTAccuracy = accuracy_score(Y_test, X_Test_DTPrediction)\n",
    "print('Accuracy Score on the Test Data: ', Test_Data_DTAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       298\n",
      "           1       0.78      0.71      0.75       298\n",
      "\n",
      "    accuracy                           0.76       596\n",
      "   macro avg       0.76      0.76      0.76       596\n",
      "weighted avg       0.76      0.76      0.76       596\n",
      "\n",
      "[[238  60]\n",
      " [ 85 213]]\n",
      "0.5152391393659149\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, X_Test_DTPrediction))\n",
    "print(confusion_matrix(Y_test, X_Test_DTPrediction))\n",
    "print(matthews_corrcoef(Y_test, X_Test_DTPrediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Trained-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Logistic_Regression.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model = pickle.load(open('D:\\\\Semester 4\\\\Natural Language Processing\\\\Lab Praktikum\\\\Research Methodology Project\\\\Logistic_Regression.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = X_test[3]\n",
    "# print(X_String[3])\n",
    "\n",
    "# prediction = model.predict(X_new)\n",
    "# print(prediction)\n",
    "\n",
    "# if(prediction[0] == 0):\n",
    "#     print(\"Non-Stress Text\")\n",
    "# else:\n",
    "#     print(\"Stress Text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
